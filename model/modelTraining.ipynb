{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\lib\\site-packages\\scipy\\__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "import copy\n",
    "import argparse\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from collections import deque\n",
    "\n",
    "import cv2 as cv\n",
    "import mediapipe as mp\n",
    "\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros((0,33))\n",
    "cnt = 0\n",
    "for j in range(4):\n",
    "    for i in range(7):\n",
    "        data_path = f'./model/point_history_classifier/{j}/point_history_{i}.csv'\n",
    "        tmp = pd.read_csv(data_path)\n",
    "        tmp = np.array(tmp)\n",
    "        cnt += tmp.shape[0]\n",
    "        data = np.vstack((data,tmp))\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = data[::21,0].flatten()\n",
    "data = data[:,1:].reshape(int(cnt/21),1,21,32)\n",
    "label = keras.utils.to_categorical(label, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21X32 -> 16X42 변환\n",
    "hdata = np.zeros((int(cnt/21),1,16,42))\n",
    "for i in range(int(cnt/21)):\n",
    "    for j in range(32):\n",
    "        k = 0\n",
    "        if j%2:\n",
    "            k=1\n",
    "        hdata[i,0,j//2,k::2] = data[i,0,:,j]\n",
    "data = hdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = label.reshape(int(cnt/21),1,7).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(hdata.shape[0]):\n",
    "    for j in range(15,0,-1):\n",
    "        hdata[i,0,j,:] -= hdata[i,0,j-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((hdata,label)).shuffle(buffer_size=int(cnt/21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "def is_test(x, y):\n",
    "    return x % 4 == 0\n",
    "\n",
    "def is_train(x, y):\n",
    "    return not is_test(x, y)\n",
    "\n",
    "recover = lambda x,y: y\n",
    "\n",
    "test_dataset = dataset.enumerate() \\\n",
    "                    .filter(is_test) \\\n",
    "                    .map(recover)\n",
    "\n",
    "train_dataset = dataset.enumerate() \\\n",
    "                    .filter(is_train) \\\n",
    "                    .map(recover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn= tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(64,input_shape = (16,42), activation = 'ReLU'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(128, activation = 'ReLU'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(256, activation = 'ReLU'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(256, activation = 'ReLU'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(128, activation = 'ReLU'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Flatten(),                         \n",
    "    tf.keras.layers.Dense(7, activation='softmax'),   \n",
    "])\n",
    "\n",
    "\n",
    "dnn.compile(optimizer = 'adam',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "  17504/Unknown - 38s 2ms/step - loss: 0.5800 - accuracy: 0.7786\n",
      "Epoch 1: loss improved from inf to 0.57972, saving model to ./DNN\\1_0.7787.h5\n",
      "17512/17512 [==============================] - 38s 2ms/step - loss: 0.5797 - accuracy: 0.7787\n",
      "Epoch 2/32\n",
      "17493/17512 [============================>.] - ETA: 0s - loss: 0.2837 - accuracy: 0.9032\n",
      "Epoch 2: loss improved from 0.57972 to 0.28373, saving model to ./DNN\\2_0.9033.h5\n",
      "17512/17512 [==============================] - 38s 2ms/step - loss: 0.2837 - accuracy: 0.9033\n",
      "Epoch 3/32\n",
      "17501/17512 [============================>.] - ETA: 0s - loss: 0.2212 - accuracy: 0.9286\n",
      "Epoch 3: loss improved from 0.28373 to 0.22134, saving model to ./DNN\\3_0.9286.h5\n",
      "17512/17512 [==============================] - 41s 2ms/step - loss: 0.2213 - accuracy: 0.9286\n",
      "Epoch 4/32\n",
      "17497/17512 [============================>.] - ETA: 0s - loss: 0.1967 - accuracy: 0.9390\n",
      "Epoch 4: loss improved from 0.22134 to 0.19670, saving model to ./DNN\\4_0.9390.h5\n",
      "17512/17512 [==============================] - 46s 3ms/step - loss: 0.1967 - accuracy: 0.9390\n",
      "Epoch 5/32\n",
      "17504/17512 [============================>.] - ETA: 0s - loss: 0.1901 - accuracy: 0.9437\n",
      "Epoch 5: loss improved from 0.19670 to 0.19024, saving model to ./DNN\\5_0.9436.h5\n",
      "17512/17512 [==============================] - 47s 3ms/step - loss: 0.1902 - accuracy: 0.9436\n",
      "Epoch 6/32\n",
      "17512/17512 [==============================] - ETA: 0s - loss: 0.1806 - accuracy: 0.9507\n",
      "Epoch 6: loss improved from 0.19024 to 0.18065, saving model to ./DNN\\6_0.9507.h5\n",
      "17512/17512 [==============================] - 41s 2ms/step - loss: 0.1806 - accuracy: 0.9507\n",
      "Epoch 7/32\n",
      "17495/17512 [============================>.] - ETA: 0s - loss: 0.1764 - accuracy: 0.9504\n",
      "Epoch 7: loss improved from 0.18065 to 0.17621, saving model to ./DNN\\7_0.9505.h5\n",
      "17512/17512 [==============================] - 40s 2ms/step - loss: 0.1762 - accuracy: 0.9505\n",
      "Epoch 8/32\n",
      "17494/17512 [============================>.] - ETA: 0s - loss: 0.1925 - accuracy: 0.9509\n",
      "Epoch 8: loss did not improve from 0.17621\n",
      "17512/17512 [==============================] - 41s 2ms/step - loss: 0.1923 - accuracy: 0.9509\n",
      "Epoch 9/32\n",
      "17512/17512 [==============================] - ETA: 0s - loss: 0.1947 - accuracy: 0.9522\n",
      "Epoch 9: loss did not improve from 0.17621\n",
      "17512/17512 [==============================] - 41s 2ms/step - loss: 0.1947 - accuracy: 0.9522\n",
      "Epoch 10/32\n",
      "17508/17512 [============================>.] - ETA: 0s - loss: 0.1936 - accuracy: 0.9550\n",
      "Epoch 10: loss did not improve from 0.17621\n",
      "17512/17512 [==============================] - 41s 2ms/step - loss: 0.1936 - accuracy: 0.9551\n",
      "Epoch 11/32\n",
      "17505/17512 [============================>.] - ETA: 0s - loss: 0.1917 - accuracy: 0.9553\n",
      "Epoch 11: loss did not improve from 0.17621\n",
      "17512/17512 [==============================] - 41s 2ms/step - loss: 0.1917 - accuracy: 0.9553\n",
      "Epoch 12/32\n",
      "17495/17512 [============================>.] - ETA: 0s - loss: 0.1845 - accuracy: 0.9564\n",
      "Epoch 12: loss did not improve from 0.17621\n",
      "17512/17512 [==============================] - 42s 2ms/step - loss: 0.1843 - accuracy: 0.9565\n",
      "Epoch 13/32\n",
      "17509/17512 [============================>.] - ETA: 0s - loss: 0.2030 - accuracy: 0.9576\n",
      "Epoch 13: loss did not improve from 0.17621\n",
      "17512/17512 [==============================] - 42s 2ms/step - loss: 0.2030 - accuracy: 0.9576\n",
      "Epoch 14/32\n",
      "17502/17512 [============================>.] - ETA: 0s - loss: 0.2135 - accuracy: 0.9561\n",
      "Epoch 14: loss did not improve from 0.17621\n",
      "17512/17512 [==============================] - 56s 3ms/step - loss: 0.2134 - accuracy: 0.9561\n",
      "Epoch 15/32\n",
      "17506/17512 [============================>.] - ETA: 0s - loss: 0.2003 - accuracy: 0.9580\n",
      "Epoch 15: loss did not improve from 0.17621\n",
      "17512/17512 [==============================] - 82s 5ms/step - loss: 0.2009 - accuracy: 0.9579\n",
      "Epoch 16/32\n",
      "17509/17512 [============================>.] - ETA: 0s - loss: 0.2093 - accuracy: 0.9571\n",
      "Epoch 16: loss did not improve from 0.17621\n",
      "17512/17512 [==============================] - 123s 7ms/step - loss: 0.2094 - accuracy: 0.9570\n",
      "Epoch 17/32\n",
      "17508/17512 [============================>.] - ETA: 0s - loss: 0.2077 - accuracy: 0.9555\n",
      "Epoch 17: loss did not improve from 0.17621\n",
      "17512/17512 [==============================] - 180s 10ms/step - loss: 0.2077 - accuracy: 0.9555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11a808838b0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='loss',patience=10)\n",
    "check_point = tf.keras.callbacks.ModelCheckpoint(filepath='./DNN/{epoch}_{accuracy:.4f}.h5', monitor='loss', save_best_only=True, verbose=1)\n",
    "dnn.fit(train_dataset, epochs = 32, callbacks=[es, check_point])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn = tf.keras.models.load_model('./dnn/7_0.9505.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5838/5838 [==============================] - 15s 3ms/step - loss: 0.0390 - accuracy: 0.9875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03904910385608673, 0.9874957203865051]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(units = 50, return_sequences=True ,input_shape = (16,42)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.LSTM(units = 50),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(7, activation='softmax'),   \n",
    "    tf.keras.layers.Flatten()                         \n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "  25834/Unknown - 216s 8ms/step - loss: 0.3267 - accuracy: 0.8862\n",
      "Epoch 1: loss improved from inf to 0.32667, saving model to ./motionmodel\\1_0.8862.h5\n",
      "25838/25838 [==============================] - 218s 8ms/step - loss: 0.3267 - accuracy: 0.8862\n",
      "Epoch 2/32\n",
      "25836/25838 [============================>.] - ETA: 0s - loss: 0.0592 - accuracy: 0.9836\n",
      "Epoch 2: loss improved from 0.32667 to 0.05922, saving model to ./motionmodel\\2_0.9836.h5\n",
      "25838/25838 [==============================] - 218s 8ms/step - loss: 0.0592 - accuracy: 0.9836\n",
      "Epoch 3/32\n",
      "25838/25838 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 0.9907\n",
      "Epoch 3: loss improved from 0.05922 to 0.03523, saving model to ./motionmodel\\3_0.9907.h5\n",
      "25838/25838 [==============================] - 218s 8ms/step - loss: 0.0352 - accuracy: 0.9907\n",
      "Epoch 4/32\n",
      "25834/25838 [============================>.] - ETA: 0s - loss: 0.0279 - accuracy: 0.9928\n",
      "Epoch 4: loss improved from 0.03523 to 0.02787, saving model to ./motionmodel\\4_0.9928.h5\n",
      "25838/25838 [==============================] - 215s 8ms/step - loss: 0.0279 - accuracy: 0.9928\n",
      "Epoch 5/32\n",
      "25837/25838 [============================>.] - ETA: 0s - loss: 0.0197 - accuracy: 0.9952\n",
      "Epoch 5: loss improved from 0.02787 to 0.01966, saving model to ./motionmodel\\5_0.9952.h5\n",
      "25838/25838 [==============================] - 216s 8ms/step - loss: 0.0197 - accuracy: 0.9952\n",
      "Epoch 6/32\n",
      "25836/25838 [============================>.] - ETA: 0s - loss: 0.0171 - accuracy: 0.9958\n",
      "Epoch 6: loss improved from 0.01966 to 0.01710, saving model to ./motionmodel\\6_0.9958.h5\n",
      "25838/25838 [==============================] - 226s 9ms/step - loss: 0.0171 - accuracy: 0.9958\n",
      "Epoch 7/32\n",
      "25838/25838 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9961\n",
      "Epoch 7: loss did not improve from 0.01710\n",
      "25838/25838 [==============================] - 317s 12ms/step - loss: 0.0173 - accuracy: 0.9961\n",
      "Epoch 8/32\n",
      "25838/25838 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9964\n",
      "Epoch 8: loss improved from 0.01710 to 0.01599, saving model to ./motionmodel\\8_0.9964.h5\n",
      "25838/25838 [==============================] - 335s 13ms/step - loss: 0.0160 - accuracy: 0.9964\n",
      "Epoch 9/32\n",
      "25835/25838 [============================>.] - ETA: 0s - loss: 0.0151 - accuracy: 0.9966\n",
      "Epoch 9: loss improved from 0.01599 to 0.01510, saving model to ./motionmodel\\9_0.9966.h5\n",
      "25838/25838 [==============================] - 319s 12ms/step - loss: 0.0151 - accuracy: 0.9966\n",
      "Epoch 10/32\n",
      "25835/25838 [============================>.] - ETA: 0s - loss: 0.0118 - accuracy: 0.9975\n",
      "Epoch 10: loss improved from 0.01510 to 0.01183, saving model to ./motionmodel\\10_0.9975.h5\n",
      "25838/25838 [==============================] - 335s 13ms/step - loss: 0.0118 - accuracy: 0.9975\n",
      "Epoch 11/32\n",
      "25834/25838 [============================>.] - ETA: 0s - loss: 0.0139 - accuracy: 0.9970\n",
      "Epoch 11: loss did not improve from 0.01183\n",
      "25838/25838 [==============================] - 330s 13ms/step - loss: 0.0139 - accuracy: 0.9970\n",
      "Epoch 12/32\n",
      "25834/25838 [============================>.] - ETA: 0s - loss: 0.0107 - accuracy: 0.9973\n",
      "Epoch 12: loss improved from 0.01183 to 0.01070, saving model to ./motionmodel\\12_0.9973.h5\n",
      "25838/25838 [==============================] - 328s 13ms/step - loss: 0.0107 - accuracy: 0.9973\n",
      "Epoch 13/32\n",
      "25837/25838 [============================>.] - ETA: 0s - loss: 0.0123 - accuracy: 0.9974\n",
      "Epoch 13: loss did not improve from 0.01070\n",
      "25838/25838 [==============================] - 325s 13ms/step - loss: 0.0123 - accuracy: 0.9974\n",
      "Epoch 14/32\n",
      "25836/25838 [============================>.] - ETA: 0s - loss: 0.0091 - accuracy: 0.9981\n",
      "Epoch 14: loss improved from 0.01070 to 0.00906, saving model to ./motionmodel\\14_0.9981.h5\n",
      "25838/25838 [==============================] - 299s 12ms/step - loss: 0.0091 - accuracy: 0.9981\n",
      "Epoch 15/32\n",
      "25836/25838 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.9973\n",
      "Epoch 15: loss did not improve from 0.00906\n",
      "25838/25838 [==============================] - 228s 9ms/step - loss: 0.0114 - accuracy: 0.9973\n",
      "Epoch 16/32\n",
      "25837/25838 [============================>.] - ETA: 0s - loss: 0.0111 - accuracy: 0.9979\n",
      "Epoch 16: loss did not improve from 0.00906\n",
      "25838/25838 [==============================] - 205s 8ms/step - loss: 0.0111 - accuracy: 0.9979\n",
      "Epoch 17/32\n",
      "25835/25838 [============================>.] - ETA: 0s - loss: 0.0083 - accuracy: 0.9983\n",
      "Epoch 17: loss improved from 0.00906 to 0.00826, saving model to ./motionmodel\\17_0.9983.h5\n",
      "25838/25838 [==============================] - 211s 8ms/step - loss: 0.0083 - accuracy: 0.9983\n",
      "Epoch 18/32\n",
      "25836/25838 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.9979\n",
      "Epoch 18: loss did not improve from 0.00826\n",
      "25838/25838 [==============================] - 214s 8ms/step - loss: 0.0104 - accuracy: 0.9979\n",
      "Epoch 19/32\n",
      "25833/25838 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9985\n",
      "Epoch 19: loss improved from 0.00826 to 0.00692, saving model to ./motionmodel\\19_0.9985.h5\n",
      "25838/25838 [==============================] - 186s 7ms/step - loss: 0.0069 - accuracy: 0.9985\n",
      "Epoch 20/32\n",
      "25835/25838 [============================>.] - ETA: 0s - loss: 0.0085 - accuracy: 0.9985\n",
      "Epoch 20: loss did not improve from 0.00692\n",
      "25838/25838 [==============================] - 204s 8ms/step - loss: 0.0085 - accuracy: 0.9985\n",
      "Epoch 21/32\n",
      "25833/25838 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.9980\n",
      "Epoch 21: loss did not improve from 0.00692\n",
      "25838/25838 [==============================] - 213s 8ms/step - loss: 0.0100 - accuracy: 0.9980\n",
      "Epoch 22/32\n",
      "25833/25838 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.9984\n",
      "Epoch 22: loss did not improve from 0.00692\n",
      "25838/25838 [==============================] - 207s 8ms/step - loss: 0.0079 - accuracy: 0.9984\n",
      "Epoch 23/32\n",
      "25836/25838 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9983\n",
      "Epoch 23: loss did not improve from 0.00692\n",
      "25838/25838 [==============================] - 209s 8ms/step - loss: 0.0072 - accuracy: 0.9983\n",
      "Epoch 24/32\n",
      "25838/25838 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9986\n",
      "Epoch 24: loss did not improve from 0.00692\n",
      "25838/25838 [==============================] - 271s 10ms/step - loss: 0.0082 - accuracy: 0.9986\n",
      "Epoch 25/32\n",
      "25834/25838 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9985\n",
      "Epoch 25: loss improved from 0.00692 to 0.00622, saving model to ./motionmodel\\25_0.9985.h5\n",
      "25838/25838 [==============================] - 247s 10ms/step - loss: 0.0062 - accuracy: 0.9985\n",
      "Epoch 26/32\n",
      "25833/25838 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9986\n",
      "Epoch 26: loss did not improve from 0.00622\n",
      "25838/25838 [==============================] - 220s 8ms/step - loss: 0.0062 - accuracy: 0.9986\n",
      "Epoch 27/32\n",
      "25835/25838 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.9984\n",
      "Epoch 27: loss did not improve from 0.00622\n",
      "25838/25838 [==============================] - 235s 9ms/step - loss: 0.0088 - accuracy: 0.9984\n",
      "Epoch 28/32\n",
      "25837/25838 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9984\n",
      "Epoch 28: loss did not improve from 0.00622\n",
      "25838/25838 [==============================] - 281s 11ms/step - loss: 0.0073 - accuracy: 0.9984\n",
      "Epoch 29/32\n",
      "25836/25838 [============================>.] - ETA: 0s - loss: 0.0086 - accuracy: 0.9985\n",
      "Epoch 29: loss did not improve from 0.00622\n",
      "25838/25838 [==============================] - 351s 14ms/step - loss: 0.0086 - accuracy: 0.9985\n",
      "Epoch 30/32\n",
      "25838/25838 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9981\n",
      "Epoch 30: loss did not improve from 0.00622\n",
      "25838/25838 [==============================] - 376s 15ms/step - loss: 0.0091 - accuracy: 0.9981\n",
      "Epoch 31/32\n",
      "25836/25838 [============================>.] - ETA: 0s - loss: 0.0086 - accuracy: 0.9981\n",
      "Epoch 31: loss did not improve from 0.00622\n",
      "25838/25838 [==============================] - 350s 14ms/step - loss: 0.0086 - accuracy: 0.9981\n",
      "Epoch 32/32\n",
      "25834/25838 [============================>.] - ETA: 0s - loss: 0.0085 - accuracy: 0.9988\n",
      "Epoch 32: loss did not improve from 0.00622\n",
      "25838/25838 [==============================] - 333s 13ms/step - loss: 0.0085 - accuracy: 0.9988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20f68b525b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='loss',patience=10)\n",
    "check_point = tf.keras.callbacks.ModelCheckpoint(filepath='./motionmodel/{epoch}_{accuracy:.4f}.h5', monitor='loss', save_best_only=True, verbose=1)\n",
    "model.fit(train_dataset, epochs = 32, callbacks=[es, check_point])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./motionmodel/25_0.9985.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8613/8613 [==============================] - 21s 2ms/step - loss: 0.0014 - accuracy: 0.9995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.001400164095684886, 0.9995355606079102]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_l= tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(units = 16, return_sequences=True ,input_shape = (16,42)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.LSTM(units = 16),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(7, activation='softmax'),   \n",
    "    tf.keras.layers.Flatten()                         \n",
    "])\n",
    "\n",
    "\n",
    "model_l.compile(optimizer = 'adam',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "  17507/Unknown - 125s 7ms/step - loss: 0.5290 - accuracy: 0.8126\n",
      "Epoch 1: loss improved from inf to 0.52900, saving model to ./Lstm\\1_0.8126.h5\n",
      "17512/17512 [==============================] - 125s 7ms/step - loss: 0.5290 - accuracy: 0.8126\n",
      "Epoch 2/32\n",
      "17510/17512 [============================>.] - ETA: 0s - loss: 0.1678 - accuracy: 0.9461\n",
      "Epoch 2: loss improved from 0.52900 to 0.16779, saving model to ./Lstm\\2_0.9461.h5\n",
      "17512/17512 [==============================] - 106s 6ms/step - loss: 0.1678 - accuracy: 0.9461\n",
      "Epoch 3/32\n",
      "17511/17512 [============================>.] - ETA: 0s - loss: 0.1178 - accuracy: 0.9637\n",
      "Epoch 3: loss improved from 0.16779 to 0.11777, saving model to ./Lstm\\3_0.9637.h5\n",
      "17512/17512 [==============================] - 121s 7ms/step - loss: 0.1178 - accuracy: 0.9637\n",
      "Epoch 4/32\n",
      "17506/17512 [============================>.] - ETA: 0s - loss: 0.0873 - accuracy: 0.9737\n",
      "Epoch 4: loss improved from 0.11777 to 0.08732, saving model to ./Lstm\\4_0.9737.h5\n",
      "17512/17512 [==============================] - 133s 8ms/step - loss: 0.0873 - accuracy: 0.9737\n",
      "Epoch 5/32\n",
      "17507/17512 [============================>.] - ETA: 0s - loss: 0.0729 - accuracy: 0.9765\n",
      "Epoch 5: loss improved from 0.08732 to 0.07284, saving model to ./Lstm\\5_0.9765.h5\n",
      "17512/17512 [==============================] - 134s 8ms/step - loss: 0.0728 - accuracy: 0.9765\n",
      "Epoch 6/32\n",
      "17510/17512 [============================>.] - ETA: 0s - loss: 0.0651 - accuracy: 0.9805\n",
      "Epoch 6: loss improved from 0.07284 to 0.06513, saving model to ./Lstm\\6_0.9805.h5\n",
      "17512/17512 [==============================] - 124s 7ms/step - loss: 0.0651 - accuracy: 0.9805\n",
      "Epoch 7/32\n",
      "17512/17512 [==============================] - ETA: 0s - loss: 0.0560 - accuracy: 0.9827\n",
      "Epoch 7: loss improved from 0.06513 to 0.05602, saving model to ./Lstm\\7_0.9827.h5\n",
      "17512/17512 [==============================] - 141s 8ms/step - loss: 0.0560 - accuracy: 0.9827\n",
      "Epoch 8/32\n",
      "17506/17512 [============================>.] - ETA: 0s - loss: 0.0519 - accuracy: 0.9850\n",
      "Epoch 8: loss improved from 0.05602 to 0.05194, saving model to ./Lstm\\8_0.9850.h5\n",
      "17512/17512 [==============================] - 111s 6ms/step - loss: 0.0519 - accuracy: 0.9850\n",
      "Epoch 9/32\n",
      "17511/17512 [============================>.] - ETA: 0s - loss: 0.0408 - accuracy: 0.9884\n",
      "Epoch 9: loss improved from 0.05194 to 0.04076, saving model to ./Lstm\\9_0.9884.h5\n",
      "17512/17512 [==============================] - 100s 6ms/step - loss: 0.0408 - accuracy: 0.9884\n",
      "Epoch 10/32\n",
      "17505/17512 [============================>.] - ETA: 0s - loss: 0.0426 - accuracy: 0.9882\n",
      "Epoch 10: loss did not improve from 0.04076\n",
      "17512/17512 [==============================] - 133s 8ms/step - loss: 0.0426 - accuracy: 0.9882\n",
      "Epoch 11/32\n",
      "17504/17512 [============================>.] - ETA: 0s - loss: 0.0385 - accuracy: 0.9895\n",
      "Epoch 11: loss improved from 0.04076 to 0.03855, saving model to ./Lstm\\11_0.9895.h5\n",
      "17512/17512 [==============================] - 115s 7ms/step - loss: 0.0386 - accuracy: 0.9895\n",
      "Epoch 12/32\n",
      "17505/17512 [============================>.] - ETA: 0s - loss: 0.0367 - accuracy: 0.9902\n",
      "Epoch 12: loss improved from 0.03855 to 0.03670, saving model to ./Lstm\\12_0.9902.h5\n",
      "17512/17512 [==============================] - 101s 6ms/step - loss: 0.0367 - accuracy: 0.9902\n",
      "Epoch 13/32\n",
      "17512/17512 [==============================] - ETA: 0s - loss: 0.0306 - accuracy: 0.9911\n",
      "Epoch 13: loss improved from 0.03670 to 0.03057, saving model to ./Lstm\\13_0.9911.h5\n",
      "17512/17512 [==============================] - 102s 6ms/step - loss: 0.0306 - accuracy: 0.9911\n",
      "Epoch 14/32\n",
      "17510/17512 [============================>.] - ETA: 0s - loss: 0.0293 - accuracy: 0.9921\n",
      "Epoch 14: loss improved from 0.03057 to 0.02925, saving model to ./Lstm\\14_0.9921.h5\n",
      "17512/17512 [==============================] - 107s 6ms/step - loss: 0.0293 - accuracy: 0.9921\n",
      "Epoch 15/32\n",
      "17508/17512 [============================>.] - ETA: 0s - loss: 0.0307 - accuracy: 0.9921\n",
      "Epoch 15: loss did not improve from 0.02925\n",
      "17512/17512 [==============================] - 127s 7ms/step - loss: 0.0307 - accuracy: 0.9921\n",
      "Epoch 16/32\n",
      "17512/17512 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 0.9926\n",
      "Epoch 16: loss improved from 0.02925 to 0.02681, saving model to ./Lstm\\16_0.9926.h5\n",
      "17512/17512 [==============================] - 99s 6ms/step - loss: 0.0268 - accuracy: 0.9926\n",
      "Epoch 17/32\n",
      "17504/17512 [============================>.] - ETA: 0s - loss: 0.0238 - accuracy: 0.9930\n",
      "Epoch 17: loss improved from 0.02681 to 0.02396, saving model to ./Lstm\\17_0.9929.h5\n",
      "17512/17512 [==============================] - 101s 6ms/step - loss: 0.0240 - accuracy: 0.9929\n",
      "Epoch 18/32\n",
      "17511/17512 [============================>.] - ETA: 0s - loss: 0.0234 - accuracy: 0.9935\n",
      "Epoch 18: loss improved from 0.02396 to 0.02336, saving model to ./Lstm\\18_0.9935.h5\n",
      "17512/17512 [==============================] - 100s 6ms/step - loss: 0.0234 - accuracy: 0.9935\n",
      "Epoch 19/32\n",
      "17509/17512 [============================>.] - ETA: 0s - loss: 0.0259 - accuracy: 0.9930\n",
      "Epoch 19: loss did not improve from 0.02336\n",
      "17512/17512 [==============================] - 100s 6ms/step - loss: 0.0259 - accuracy: 0.9930\n",
      "Epoch 20/32\n",
      "17508/17512 [============================>.] - ETA: 0s - loss: 0.0195 - accuracy: 0.9946\n",
      "Epoch 20: loss improved from 0.02336 to 0.01945, saving model to ./Lstm\\20_0.9946.h5\n",
      "17512/17512 [==============================] - 107s 6ms/step - loss: 0.0195 - accuracy: 0.9946\n",
      "Epoch 21/32\n",
      "17511/17512 [============================>.] - ETA: 0s - loss: 0.0247 - accuracy: 0.9929\n",
      "Epoch 21: loss did not improve from 0.01945\n",
      "17512/17512 [==============================] - 105s 6ms/step - loss: 0.0247 - accuracy: 0.9929\n",
      "Epoch 22/32\n",
      "17506/17512 [============================>.] - ETA: 0s - loss: 0.0198 - accuracy: 0.9947\n",
      "Epoch 22: loss did not improve from 0.01945\n",
      "17512/17512 [==============================] - 111s 6ms/step - loss: 0.0198 - accuracy: 0.9947\n",
      "Epoch 23/32\n",
      "17507/17512 [============================>.] - ETA: 0s - loss: 0.0214 - accuracy: 0.9947\n",
      "Epoch 23: loss did not improve from 0.01945\n",
      "17512/17512 [==============================] - 136s 8ms/step - loss: 0.0214 - accuracy: 0.9947\n",
      "Epoch 24/32\n",
      "17506/17512 [============================>.] - ETA: 0s - loss: 0.0191 - accuracy: 0.9946\n",
      "Epoch 24: loss improved from 0.01945 to 0.01907, saving model to ./Lstm\\24_0.9946.h5\n",
      "17512/17512 [==============================] - 123s 7ms/step - loss: 0.0191 - accuracy: 0.9946\n",
      "Epoch 25/32\n",
      "17512/17512 [==============================] - ETA: 0s - loss: 0.0212 - accuracy: 0.9946\n",
      "Epoch 25: loss did not improve from 0.01907\n",
      "17512/17512 [==============================] - 115s 7ms/step - loss: 0.0212 - accuracy: 0.9946\n",
      "Epoch 26/32\n",
      "17509/17512 [============================>.] - ETA: 0s - loss: 0.0208 - accuracy: 0.9943\n",
      "Epoch 26: loss did not improve from 0.01907\n",
      "17512/17512 [==============================] - 103s 6ms/step - loss: 0.0208 - accuracy: 0.9943\n",
      "Epoch 27/32\n",
      "17507/17512 [============================>.] - ETA: 0s - loss: 0.0193 - accuracy: 0.9954\n",
      "Epoch 27: loss did not improve from 0.01907\n",
      "17512/17512 [==============================] - 101s 6ms/step - loss: 0.0193 - accuracy: 0.9954\n",
      "Epoch 28/32\n",
      "17511/17512 [============================>.] - ETA: 0s - loss: 0.0165 - accuracy: 0.9955\n",
      "Epoch 28: loss improved from 0.01907 to 0.01647, saving model to ./Lstm\\28_0.9955.h5\n",
      "17512/17512 [==============================] - 99s 6ms/step - loss: 0.0165 - accuracy: 0.9955\n",
      "Epoch 29/32\n",
      "17508/17512 [============================>.] - ETA: 0s - loss: 0.0188 - accuracy: 0.9951\n",
      "Epoch 29: loss did not improve from 0.01647\n",
      "17512/17512 [==============================] - 103s 6ms/step - loss: 0.0188 - accuracy: 0.9951\n",
      "Epoch 30/32\n",
      "17509/17512 [============================>.] - ETA: 0s - loss: 0.0179 - accuracy: 0.9951\n",
      "Epoch 30: loss did not improve from 0.01647\n",
      "17512/17512 [==============================] - 127s 7ms/step - loss: 0.0179 - accuracy: 0.9951\n",
      "Epoch 31/32\n",
      "17509/17512 [============================>.] - ETA: 0s - loss: 0.0185 - accuracy: 0.9953\n",
      "Epoch 31: loss did not improve from 0.01647\n",
      "17512/17512 [==============================] - 107s 6ms/step - loss: 0.0185 - accuracy: 0.9953\n",
      "Epoch 32/32\n",
      "17508/17512 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.9960\n",
      "Epoch 32: loss improved from 0.01647 to 0.01315, saving model to ./Lstm\\32_0.9960.h5\n",
      "17512/17512 [==============================] - 111s 6ms/step - loss: 0.0131 - accuracy: 0.9960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ce125fef70>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='loss',patience=10)\n",
    "check_point = tf.keras.callbacks.ModelCheckpoint(filepath='./Lstm/{epoch}_{accuracy:.4f}.h5', monitor='loss', save_best_only=True, verbose=1)\n",
    "model_l.fit(train_dataset, epochs = 32, callbacks=[es, check_point])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_l = tf.keras.models.load_model('./Lstm/32_0.9960.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5838/5838 [==============================] - 13s 2ms/step - loss: 0.0172 - accuracy: 0.9949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.017216941341757774, 0.9948612451553345]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_l.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 16, 50)            18600     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16, 50)            0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 50)                20200     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 7)                 357       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 7)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 39,157\n",
      "Trainable params: 39,157\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f5583cf1d9466b5c27e75c89cc6b383bed5736d6b16c51c8074d8690011a952"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
